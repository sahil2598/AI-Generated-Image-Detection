{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from struct import unpack\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images and move them into a single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/AIRecognition.zip -d AIRecognition\n",
    "!unzip /content/drive/MyDrive/Datasets/art_images.zip -d art_images\n",
    "!unzip /content/drive/MyDrive/Datasets/Abstract_gallery.zip -d Abstract_gallery\n",
    "! mv /content/Abstract_gallery /content/AIRecognition/real/Abstract_gallery\n",
    "!mv /content/art_images/art_images /content/AIRecognition/real/art_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete files with invalid extensions and rename JPEG to JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '/content/AIRecognition/real'\n",
    "\n",
    "files = os.listdir(directory_path)\n",
    "file_extensions = [os.path.splitext(file)[1] for file in files if os.path.isfile(os.path.join(directory_path, file))]\n",
    "unique_extensions = set(file_extensions)\n",
    "print(unique_extensions)\n",
    "\n",
    "! rm /content/AIRecognition/real/*.txt\n",
    "! rm /content/AIRecognition/fakeV2/fake-v2/sort\n",
    "! rm /content/AIRecognition/fakeV2/fake-v2/dataset-metadata.json\n",
    "\n",
    "files = os.listdir(directory_path)\n",
    "for file in files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    if os.path.isfile(file_path) and file.lower().endswith('.jpeg'):\n",
    "        new_file_path = os.path.join(directory_path, file[:-5] + '.jpg')\n",
    "        os.rename(file_path, new_file_path)\n",
    "        print(f\"Renamed {file_path} to {new_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove corrupted images using PIL Image library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def is_image_corrupted(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img.verify()  # Verify that it is an image\n",
    "        return False\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print(f'Corrupted image: {image_path}')\n",
    "        return True\n",
    "\n",
    "directory = '/content/AIRecognition/real/'  # done for /fake directory also\n",
    "for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            image_path = os.path.join(root, file)\n",
    "            if is_image_corrupted(image_path):\n",
    "              os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Remove images that canno tbe decoded using tensorflow image library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/content/AIRecognition/real/'\n",
    "def preprocess_image(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    try:\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [img_height, img_width])\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        print(f\"Error decoding image: {file_path}\")\n",
    "        return None\n",
    "    return image\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            image_path = os.path.join(root, file)\n",
    "            preprocess_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional check for corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "marker_mapping = {\n",
    "    0xffd8: \"Start of Image\",\n",
    "    0xffe0: \"Application Default Header\",\n",
    "    0xffdb: \"Quantization Table\",\n",
    "    0xffc0: \"Start of Frame\",\n",
    "    0xffc4: \"Define Huffman Table\",\n",
    "    0xffda: \"Start of Scan\",\n",
    "    0xffd9: \"End of Image\"\n",
    "}\n",
    "\n",
    "\n",
    "class JPEG:\n",
    "  def __init__(self, image_file):\n",
    "    with open(image_file, 'rb') as f:\n",
    "        self.img_data = f.read()\n",
    "\n",
    "  def decode(self):\n",
    "    data = self.img_data\n",
    "    while(True):\n",
    "        marker, = unpack(\">H\", data[0:2])\n",
    "        if marker == 0xffd8:\n",
    "            data = data[2:]\n",
    "        elif marker == 0xffd9:\n",
    "            return\n",
    "        elif marker == 0xffda:\n",
    "            data = data[-2:]\n",
    "        else:\n",
    "            lenchunk, = unpack(\">H\", data[2:4])\n",
    "            data = data[2+lenchunk:]\n",
    "        if len(data)==0:\n",
    "            raise TypeError(\"issue reading jpeg file\")\n",
    "\n",
    "\n",
    "bads = []\n",
    "\n",
    "img_dir = '/content/AIRecognition/real/'\n",
    "for dirName, subdirList, fileList in os.walk(img_dir):\n",
    "  imagesList = fileList\n",
    "  for img in tqdm(imagesList):\n",
    "    if img.lower().endswith('.jpg'):\n",
    "      image = JPEG(img_dir + img)\n",
    "      try:\n",
    "        image.decode()\n",
    "      except:\n",
    "        bads.append(img)\n",
    "\n",
    "\n",
    "print(bads)\n",
    "for name in bads:\n",
    "  os.remove(os.path.join(img_dir, name))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
